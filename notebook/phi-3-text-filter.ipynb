{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! huggingface-cli login --token XXXXXXXXXXXXXXXXXXXXXXXxxxxxxxxx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport pandas as pd \nimport re\nimport json\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = pipeline(\"text-generation\", \n                model=\"microsoft/Phi-3-mini-128k-instruct\", \n                trust_remote_code=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"system_prompt = \"\"\"\nYou are a text classification model with the ability to filter and categorize texts based on specified topics.\n\"\"\"\n\nuser_prompt = \"\"\"\nPlease process the provided text and filter it according to the following topics:\n1. Safety\n2. Privacy\n3. Harassment\n4. Hate Speech\n5. Misinformation\n\nFor each text, determine whether it is relevant to these topics and categorize it accordingly. Return the results in JSON format, where each entry includes the original text and its classification for each topic.\n\n**Format:**\n```json\n[\n    {\n        \"classification\": {\n            \"Safety\": \"Yes/No\",\n            \"Privacy\": \"Yes/No\",\n            \"Harassment\": \"Yes/No\",\n            \"Hate Speech\": \"Yes/No\",\n            \"Misinformation\": \"Yes/No\"\n        }\n    },\n\n]\n```\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_filter(text) :\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_prompt},\n        {\"role\": \"user\", \"content\": f\"My text : {text}\" }\n    ]\n    generation_args = {\n        \"max_new_tokens\": 2048,\n        \"return_full_text\": True,\n        \"temperature\": 0.0,\n        \"do_sample\": False\n    }\n    output = pipe(messages, **generation_args)\n    return output[0]['generated_text'][3]['content']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_json_from_string(text):\n    objs = []\n    errors = []\n\n    # Use regex to find JSON-like structures in the text\n    matches = re.findall(r'{.*}', text, re.DOTALL)\n    if not matches:\n        errors.append(\"No JSON patterns found\")\n    \n    for index, json_string in enumerate(matches):\n        try:\n            # Load JSON object\n            json_obj = json.loads(json_string)\n            objs.append(json_obj)\n        except json.JSONDecodeError as e:\n            errors.append((index, json_string, f\"JSONDecodeError: {e}\"))\n        except Exception as e:\n            errors.append((index, json_string, f\"Error: {e}\"))\n\n    return objs, errors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def llm_filter(ds_name , split , target_column , save=False) : \n    \n    ds = load_dataset(ds_name , split=split)\n    text_list = ds[target_column]\n    \n    df_dict = []\n    # Process each text in the list\n    for i in tqdm(text_list, desc=\"Processing texts\"):\n        result = run_filter(i)\n        objs, errors = extract_json_from_string(result)\n\n        # Handle cases where objs or errors might be empty\n        classification = objs[0]['classification'] if objs else None\n        error_info = errors[0] if errors else None\n\n        # Append results to the list\n        df_dict.append({\n            \"text\": i,\n            \"classification\": classification,\n            \"errors\": error_info\n        })\n    \n    df = pd.DataFrame(df_dict)\n    classification_df = pd.json_normalize(df['classification'])\n    final_df = df.drop(columns=['classification']).join(classification_df)\n    if save : \n        final_df.to_csv(f\"{ds_name.rsplit('/')[-1]}-{target_column}-Filtered.csv\", index=False)\n     \n    return final_df\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = llm_filter(ds_name=\"ayoubkirouane/Small-Instruct-Alpaca_Format\" , \n                    split=\"train\" , \n                    target_column=\"response\",\n                    save=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df","metadata":{},"execution_count":null,"outputs":[]}]}
